{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyflyt","metadata":{"execution":{"iopub.status.busy":"2024-04-26T23:22:13.365787Z","iopub.execute_input":"2024-04-26T23:22:13.366326Z","iopub.status.idle":"2024-04-26T23:23:24.604724Z","shell.execute_reply.started":"2024-04-26T23:22:13.366292Z","shell.execute_reply":"2024-04-26T23:23:24.603598Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyflyt\n  Downloading PyFlyt-0.19.0-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from pyflyt) (0.58.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pyflyt) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pyflyt) (1.11.4)\nRequirement already satisfied: gymnasium in /opt/conda/lib/python3.10/site-packages (from pyflyt) (0.29.0)\nRequirement already satisfied: pettingzoo in /opt/conda/lib/python3.10/site-packages (from pyflyt) (1.24.0)\nCollecting pybullet (from pyflyt)\n  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from pyflyt) (6.0.1)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium->pyflyt) (2.2.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium->pyflyt) (4.9.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium->pyflyt) (0.0.4)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->pyflyt) (0.41.1)\nDownloading PyFlyt-0.19.0-py3-none-any.whl (197 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.0/198.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n\u001b[?25hInstalling collected packages: pybullet, pyflyt\nSuccessfully installed pybullet-3.2.6 pyflyt-0.19.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from PyFlyt.core.drones import Rocket\nimport numpy as np\n\nimport gymnasium\nimport PyFlyt.gym_envs\n\nfrom stable_baselines3 import DQN, PPO\nfrom stable_baselines3.common.evaluation import evaluate_policy\nfrom stable_baselines3.common.policies import ActorCriticPolicy\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-26T23:23:24.607065Z","iopub.execute_input":"2024-04-26T23:23:24.607833Z","iopub.status.idle":"2024-04-26T23:23:39.619188Z","shell.execute_reply.started":"2024-04-26T23:23:24.607794Z","shell.execute_reply":"2024-04-26T23:23:39.618313Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"pybullet build time: Nov 28 2023 23:45:17\n2024-04-26 23:23:30.529495: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-26 23:23:30.529622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-26 23:23:30.627689: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a DQN model with default parameters\nenv = gymnasium.make(\"PyFlyt/Rocket-Landing-v1\")\nobs, _ = env.reset()\n\n\npolicy_kwargs = {\n    \"net_arch\": [256, 256, 128],  # Neural network architecture\n}\n\nppo_params = {\n    \"policy_kwargs\": policy_kwargs,\n    \"learning_rate\": 0.0003,\n    \"clip_range\": 0.2,\n    \"batch_size\": 512,\n    \"n_steps\": 2048,  # Number of steps to collect before each policy update\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 10,  # Number of epochs to train each policy update\n    \"ent_coef\": 0.01,  # Entropy coefficient\n    \"vf_coef\": 0.5,  # Value function coefficient\n    \"max_grad_norm\": 0.5,  # Maximum gradient norm\n}\n\nmodel = PPO(\"MlpPolicy\", env, verbose=1, **ppo_params)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T23:23:39.620246Z","iopub.execute_input":"2024-04-26T23:23:39.620750Z","iopub.status.idle":"2024-04-26T23:23:45.882308Z","shell.execute_reply.started":"2024-04-26T23:23:39.620725Z","shell.execute_reply":"2024-04-26T23:23:45.881503Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[A                             \u001b[A\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the PPO model\nmodel.learn(total_timesteps=10000000)\nmodel.save(\"ppo_rocket_landing_v4\")","metadata":{"execution":{"iopub.status.busy":"2024-04-26T23:23:45.884115Z","iopub.execute_input":"2024-04-26T23:23:45.884412Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\u001b[A                             \u001b[A\nargv[0]=\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n----------------------------------\n| rollout/           |           |\n|    ep_len_mean     | 963       |\n|    ep_rew_mean     | -3.86e+04 |\n| time/              |           |\n|    fps             | 182       |\n|    iterations      | 1         |\n|    time_elapsed    | 11        |\n|    total_timesteps | 2048      |\n----------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 940          |\n|    ep_rew_mean          | -3.25e+04    |\n| time/                   |              |\n|    fps                  | 182          |\n|    iterations           | 2            |\n|    time_elapsed         | 22           |\n|    total_timesteps      | 4096         |\n| train/                  |              |\n|    approx_kl            | 0.0050703306 |\n|    clip_fraction        | 0.0236       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -9.93        |\n|    explained_variance   | 0.00119      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.61e+05     |\n|    n_updates            | 10           |\n|    policy_gradient_loss | -0.00709     |\n|    std                  | 1            |\n|    value_loss           | 5.44e+05     |\n------------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 951          |\n|    ep_rew_mean          | -3.11e+04    |\n| time/                   |              |\n|    fps                  | 186          |\n|    iterations           | 3            |\n|    time_elapsed         | 32           |\n|    total_timesteps      | 6144         |\n| train/                  |              |\n|    approx_kl            | 0.0066110156 |\n|    clip_fraction        | 0.0221       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -9.94        |\n|    explained_variance   | -0.000539    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.28e+05     |\n|    n_updates            | 20           |\n|    policy_gradient_loss | -0.00702     |\n|    std                  | 1            |\n|    value_loss           | 2.48e+05     |\n------------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 955         |\n|    ep_rew_mean          | -3.11e+04   |\n| time/                   |             |\n|    fps                  | 189         |\n|    iterations           | 4           |\n|    time_elapsed         | 43          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.003521885 |\n|    clip_fraction        | 0.00459     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -9.94       |\n|    explained_variance   | 0.00162     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.69e+05    |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.00422    |\n|    std                  | 1           |\n|    value_loss           | 3.41e+05    |\n-----------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 945          |\n|    ep_rew_mean          | -3.01e+04    |\n| time/                   |              |\n|    fps                  | 190          |\n|    iterations           | 5            |\n|    time_elapsed         | 53           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0030852326 |\n|    clip_fraction        | 0.0041       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -9.95        |\n|    explained_variance   | 0.000476     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.16e+05     |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.00537     |\n|    std                  | 1            |\n|    value_loss           | 4.39e+05     |\n------------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 957         |\n|    ep_rew_mean          | -2.95e+04   |\n| time/                   |             |\n|    fps                  | 190         |\n|    iterations           | 6           |\n|    time_elapsed         | 64          |\n|    total_timesteps      | 12288       |\n| train/                  |             |\n|    approx_kl            | 0.003162437 |\n|    clip_fraction        | 0.00298     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -9.95       |\n|    explained_variance   | 0.000716    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.21e+05    |\n|    n_updates            | 50          |\n|    policy_gradient_loss | -0.00436    |\n|    std                  | 1           |\n|    value_loss           | 2.38e+05    |\n-----------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 951          |\n|    ep_rew_mean          | -2.91e+04    |\n| time/                   |              |\n|    fps                  | 191          |\n|    iterations           | 7            |\n|    time_elapsed         | 74           |\n|    total_timesteps      | 14336        |\n| train/                  |              |\n|    approx_kl            | 0.0038604983 |\n|    clip_fraction        | 0.00869      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -9.95        |\n|    explained_variance   | 0.000795     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.16e+05     |\n|    n_updates            | 60           |\n|    policy_gradient_loss | -0.00558     |\n|    std                  | 1            |\n|    value_loss           | 2.42e+05     |\n------------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 949          |\n|    ep_rew_mean          | -2.83e+04    |\n| time/                   |              |\n|    fps                  | 191          |\n|    iterations           | 8            |\n|    time_elapsed         | 85           |\n|    total_timesteps      | 16384        |\n| train/                  |              |\n|    approx_kl            | 0.0025409611 |\n|    clip_fraction        | 0.00176      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -9.96        |\n|    explained_variance   | 0.000209     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.7e+05      |\n|    n_updates            | 70           |\n|    policy_gradient_loss | -0.00421     |\n|    std                  | 1            |\n|    value_loss           | 3.7e+05      |\n------------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 949         |\n|    ep_rew_mean          | -2.87e+04   |\n| time/                   |             |\n|    fps                  | 192         |\n|    iterations           | 9           |\n|    time_elapsed         | 95          |\n|    total_timesteps      | 18432       |\n| train/                  |             |\n|    approx_kl            | 0.005539712 |\n|    clip_fraction        | 0.025       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -9.96       |\n|    explained_variance   | 0.000164    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 8.32e+04    |\n|    n_updates            | 80          |\n|    policy_gradient_loss | -0.00612    |\n|    std                  | 1           |\n|    value_loss           | 1.7e+05     |\n-----------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 947          |\n|    ep_rew_mean          | -2.83e+04    |\n| time/                   |              |\n|    fps                  | 192          |\n|    iterations           | 10           |\n|    time_elapsed         | 106          |\n|    total_timesteps      | 20480        |\n| train/                  |              |\n|    approx_kl            | 0.0031559167 |\n|    clip_fraction        | 0.00327      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -9.96        |\n|    explained_variance   | 0.000698     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.96e+05     |\n|    n_updates            | 90           |\n|    policy_gradient_loss | -0.00352     |\n|    std                  | 1            |\n|    value_loss           | 4.01e+05     |\n------------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 946         |\n|    ep_rew_mean          | -2.76e+04   |\n| time/                   |             |\n|    fps                  | 193         |\n|    iterations           | 11          |\n|    time_elapsed         | 116         |\n|    total_timesteps      | 22528       |\n| train/                  |             |\n|    approx_kl            | 0.006451435 |\n|    clip_fraction        | 0.0314      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -9.97       |\n|    explained_variance   | 4.01e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.1e+05     |\n|    n_updates            | 100         |\n|    policy_gradient_loss | -0.0069     |\n|    std                  | 1.01        |\n|    value_loss           | 2.17e+05    |\n-----------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 948          |\n|    ep_rew_mean          | -2.77e+04    |\n| time/                   |              |\n|    fps                  | 193          |\n|    iterations           | 12           |\n|    time_elapsed         | 127          |\n|    total_timesteps      | 24576        |\n| train/                  |              |\n|    approx_kl            | 0.0042835404 |\n|    clip_fraction        | 0.00776      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -9.97        |\n|    explained_variance   | 0.000187     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1e+05        |\n|    n_updates            | 110          |\n|    policy_gradient_loss | -0.00424     |\n|    std                  | 1            |\n|    value_loss           | 1.93e+05     |\n------------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 950          |\n|    ep_rew_mean          | -2.84e+04    |\n| time/                   |              |\n|    fps                  | 193          |\n|    iterations           | 13           |\n|    time_elapsed         | 137          |\n|    total_timesteps      | 26624        |\n| train/                  |              |\n|    approx_kl            | 0.0029034624 |\n|    clip_fraction        | 0.00254      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -9.97        |\n|    explained_variance   | 0.00308      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.38e+05     |\n|    n_updates            | 120          |\n|    policy_gradient_loss | -0.0048      |\n|    std                  | 1.01         |\n|    value_loss           | 4.63e+05     |\n------------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 956         |\n|    ep_rew_mean          | -2.9e+04    |\n| time/                   |             |\n|    fps                  | 193         |\n|    iterations           | 14          |\n|    time_elapsed         | 148         |\n|    total_timesteps      | 28672       |\n| train/                  |             |\n|    approx_kl            | 0.001755052 |\n|    clip_fraction        | 0.000293    |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -9.98       |\n|    explained_variance   | 0.0013      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.06e+05    |\n|    n_updates            | 130         |\n|    policy_gradient_loss | -0.00323    |\n|    std                  | 1.01        |\n|    value_loss           | 4.25e+05    |\n-----------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 941        |\n|    ep_rew_mean          | -2.93e+04  |\n| time/                   |            |\n|    fps                  | 193        |\n|    iterations           | 15         |\n|    time_elapsed         | 158        |\n|    total_timesteps      | 30720      |\n| train/                  |            |\n|    approx_kl            | 0.00320989 |\n|    clip_fraction        | 0.00723    |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -9.98      |\n|    explained_variance   | 0.0125     |\n|    learning_rate        | 0.0003     |\n|    loss                 | 2.04e+05   |\n|    n_updates            | 140        |\n|    policy_gradient_loss | -0.00414   |\n|    std                  | 1.01       |\n|    value_loss           | 4.19e+05   |\n----------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 940          |\n|    ep_rew_mean          | -2.94e+04    |\n| time/                   |              |\n|    fps                  | 193          |\n|    iterations           | 16           |\n|    time_elapsed         | 169          |\n|    total_timesteps      | 32768        |\n| train/                  |              |\n|    approx_kl            | 0.0020168915 |\n|    clip_fraction        | 0.00112      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -9.98        |\n|    explained_variance   | 0.000254     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 3.46e+05     |\n|    n_updates            | 150          |\n|    policy_gradient_loss | -0.00391     |\n|    std                  | 1.01         |\n|    value_loss           | 6.58e+05     |\n------------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 945          |\n|    ep_rew_mean          | -3e+04       |\n| time/                   |              |\n|    fps                  | 193          |\n|    iterations           | 17           |\n|    time_elapsed         | 179          |\n|    total_timesteps      | 34816        |\n| train/                  |              |\n|    approx_kl            | 0.0044569555 |\n|    clip_fraction        | 0.0136       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -9.98        |\n|    explained_variance   | 0.00015      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.78e+05     |\n|    n_updates            | 160          |\n|    policy_gradient_loss | -0.00528     |\n|    std                  | 1.01         |\n|    value_loss           | 3.53e+05     |\n------------------------------------------\n\u001b[A                             \u001b[Aargv[0]=\n\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 945          |\n|    ep_rew_mean          | -2.97e+04    |\n| time/                   |              |\n|    fps                  | 193          |\n|    iterations           | 18           |\n|    time_elapsed         | 190          |\n|    total_timesteps      | 36864        |\n| train/                  |              |\n|    approx_kl            | 0.0032407066 |\n|    clip_fraction        | 0.00581      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -9.99        |\n|    explained_variance   | 0.00031      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.44e+05     |\n|    n_updates            | 170          |\n|    policy_gradient_loss | -0.00418     |\n|    std                  | 1.01         |\n|    value_loss           | 4.78e+05     |\n------------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 945          |\n|    ep_rew_mean          | -3.01e+04    |\n| time/                   |              |\n|    fps                  | 193          |\n|    iterations           | 19           |\n|    time_elapsed         | 200          |\n|    total_timesteps      | 38912        |\n| train/                  |              |\n|    approx_kl            | 0.0034789033 |\n|    clip_fraction        | 0.00405      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -10          |\n|    explained_variance   | 0.00116      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.36e+05     |\n|    n_updates            | 180          |\n|    policy_gradient_loss | -0.0047      |\n|    std                  | 1.01         |\n|    value_loss           | 2.67e+05     |\n------------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 947         |\n|    ep_rew_mean          | -3.01e+04   |\n| time/                   |             |\n|    fps                  | 193         |\n|    iterations           | 20          |\n|    time_elapsed         | 211         |\n|    total_timesteps      | 40960       |\n| train/                  |             |\n|    approx_kl            | 0.002094532 |\n|    clip_fraction        | 0.000586    |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -10         |\n|    explained_variance   | 0.000123    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.54e+05    |\n|    n_updates            | 190         |\n|    policy_gradient_loss | -0.00331    |\n|    std                  | 1.01        |\n|    value_loss           | 5.11e+05    |\n-----------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 947          |\n|    ep_rew_mean          | -3.03e+04    |\n| time/                   |              |\n|    fps                  | 193          |\n|    iterations           | 21           |\n|    time_elapsed         | 221          |\n|    total_timesteps      | 43008        |\n| train/                  |              |\n|    approx_kl            | 0.0038801958 |\n|    clip_fraction        | 0.00522      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -10          |\n|    explained_variance   | 0.00206      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.56e+05     |\n|    n_updates            | 200          |\n|    policy_gradient_loss | -0.0041      |\n|    std                  | 1.01         |\n|    value_loss           | 3.12e+05     |\n------------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 944         |\n|    ep_rew_mean          | -3.01e+04   |\n| time/                   |             |\n|    fps                  | 193         |\n|    iterations           | 22          |\n|    time_elapsed         | 232         |\n|    total_timesteps      | 45056       |\n| train/                  |             |\n|    approx_kl            | 0.001365014 |\n|    clip_fraction        | 0           |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -10         |\n|    explained_variance   | 7.87e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.85e+05    |\n|    n_updates            | 210         |\n|    policy_gradient_loss | -0.00276    |\n|    std                  | 1.01        |\n|    value_loss           | 3.79e+05    |\n-----------------------------------------\n\u001b[A                             \u001b[A\nargv[0]=\n\u001b[A                             \u001b[A\nargv[0]=\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the trained model\nmean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}